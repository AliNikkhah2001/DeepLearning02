{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7326079,"sourceType":"datasetVersion","datasetId":4252200},{"sourceId":7379212,"sourceType":"datasetVersion","datasetId":4288280}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"text-align: center\">\nDeep Learning HW4 </br>\nPoem generation,fine tuning\n</h1>\n","metadata":{}},{"cell_type":"markdown","source":"\n  <style>\n    table {\n      width: 100%;\n      border-collapse: collapse;\n    }\n\n    th, td {\n      border: 1px solid #dddddd;\n      text-align: left;\n      padding: 8px;\n    }\n\n    th {\n      background-color: #f2f2f2;\n    }\n\n    .box {\n      border: 1px solid #000;\n      padding: 10px;\n      width: 400px; /* Adjust the width as needed */\n      margin: 20px auto;\n    }\n  </style>\n</head>\n<body>\n\n<div class=\"box\">\n  <table>\n    <tr>\n      <th colspan=\"2\">Personal Info</th>\n    </tr>\n    <tr>\n      <td>First Name:</td>\n      <td>Ali</td>\n    </tr>\n    <tr>\n      <td>Last Name:</td>\n      <td>Nikkhah</td>\n    </tr>\n    <tr>\n      <td>Student Number:</td>\n      <td>99102445</td>\n    </tr>\n    <tr>\n      <td>Git:</td>\n      <td><a href=\"https://github.com/AliNikkhah2001/DataScience02\" target=\"_blank\">https://github.com/AliNikkhah2001/DeepLearning02</a></td>\n    </tr>\n  </table>\n</div>\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-06T07:00:51.995698Z","iopub.execute_input":"2024-01-06T07:00:51.996217Z","iopub.status.idle":"2024-01-06T07:00:52.047189Z","shell.execute_reply.started":"2024-01-06T07:00:51.996165Z","shell.execute_reply":"2024-01-06T07:00:52.045966Z"}}},{"cell_type":"markdown","source":"# Poem generator using Ferdowsi poems dataset","metadata":{}},{"cell_type":"markdown","source":"## Data Import and initialization","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install keras_preprocessing\n!pip install transformers\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:48:47.273291Z","iopub.execute_input":"2024-01-13T07:48:47.274098Z","iopub.status.idle":"2024-01-13T07:49:12.892646Z","shell.execute_reply.started":"2024-01-13T07:48:47.274063Z","shell.execute_reply":"2024-01-13T07:49:12.891403Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture\nimport tensorflow as tf\nimport numpy as np\nimport math\nimport os\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, LSTM, GRU, Embedding\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom transformers import TextDataset, DataCollatorForLanguageModeling\nfrom transformers import Trainer, TrainingArguments\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:12.894888Z","iopub.execute_input":"2024-01-13T07:49:12.895225Z","iopub.status.idle":"2024-01-13T07:49:13.013556Z","shell.execute_reply.started":"2024-01-13T07:49:12.895193Z","shell.execute_reply":"2024-01-13T07:49:13.012765Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"\nfrom pathlib import Path\nimport torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModelWithLMHead\nfrom transformers import AutoTokenizer, GPT2LMHeadModel, GPT2Config\nfrom IPython import display\n     ","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:13.014811Z","iopub.execute_input":"2024-01-13T07:49:13.015104Z","iopub.status.idle":"2024-01-13T07:49:13.020203Z","shell.execute_reply.started":"2024-01-13T07:49:13.015078Z","shell.execute_reply":"2024-01-13T07:49:13.019274Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Open text file and make dataframe ","metadata":{}},{"cell_type":"code","source":"!git lfs install\n!git clone https://huggingface.co/HooshvareLab/gpt2-fa-poetry","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:13.023194Z","iopub.execute_input":"2024-01-13T07:49:13.023852Z","iopub.status.idle":"2024-01-13T07:49:15.146161Z","shell.execute_reply.started":"2024-01-13T07:49:13.023798Z","shell.execute_reply":"2024-01-13T07:49:15.145110Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Git LFS initialized.\nfatal: destination path 'gpt2-fa-poetry' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"data_path='/kaggle/input/ferdowsi/ferdousi.txt'","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:15.147584Z","iopub.execute_input":"2024-01-13T07:49:15.147879Z","iopub.status.idle":"2024-01-13T07:49:15.152902Z","shell.execute_reply.started":"2024-01-13T07:49:15.147853Z","shell.execute_reply":"2024-01-13T07:49:15.151785Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"with open(data_path, 'r', encoding='utf-8') as f:\n    lines = f.read().split('\\n')\nlines = lines[2:]\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:15.154270Z","iopub.execute_input":"2024-01-13T07:49:15.154570Z","iopub.status.idle":"2024-01-13T07:49:15.310009Z","shell.execute_reply.started":"2024-01-13T07:49:15.154545Z","shell.execute_reply":"2024-01-13T07:49:15.309110Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model_name_or_path = \"HooshvareLab/gpt2-fa\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name_or_path,\n    bos_token='<s>', \n    eos_token='</s>', \n    pad_token='<pad>',\n    unk_token='<unk>',\n    padding_side=\"left\"\n)\ntokenizer.add_special_tokens({\n    \"bos_token\": '</s>',\n    \"eos_token\": '</s>', \n    \"pad_token\": '<pad>',\n    \"unk_token\": '<unk>'\n})\n\nconfig = AutoConfig.from_pretrained(\n    model_name_or_path,\n    bos_token_id=tokenizer(\"<s>\")[\"input_ids\"][0], \n    eos_token_id=tokenizer(\"</s>\")[\"input_ids\"][0], \n    pad_token_id=tokenizer(\"<pad>\")[\"input_ids\"][0],\n    unk_token_id=tokenizer(\"<unk>\")[\"input_ids\"][0],\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T09:23:06.422835Z","iopub.execute_input":"2024-01-13T09:23:06.423654Z","iopub.status.idle":"2024-01-13T09:23:06.705195Z","shell.execute_reply.started":"2024-01-13T09:23:06.423624Z","shell.execute_reply":"2024-01-13T09:23:06.704341Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"/kaggle/working/gpt2-fa/\")\nconfig.save_pretrained(\"/kaggle/working/gpt2-fa/\")","metadata":{"execution":{"iopub.status.busy":"2024-01-13T09:23:09.142366Z","iopub.execute_input":"2024-01-13T09:23:09.142749Z","iopub.status.idle":"2024-01-13T09:23:09.219106Z","shell.execute_reply.started":"2024-01-13T09:23:09.142719Z","shell.execute_reply":"2024-01-13T09:23:09.218099Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"df_input=[]\ndf_target=[]\ndf_concat=[]\nfor i in range(0, len(lines)-3, 2):\n    input_text= lines[i] \n    target_text = ' <s> '+ lines[i+1]+'   ' +lines[i+2] + '    ' + lines[i+3]+'  </s>  '\n    df_input.append(input_text)\n    df_target.append(target_text)\n    df_concat.append(input_text+target_text)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:16.903072Z","iopub.execute_input":"2024-01-13T07:49:16.903389Z","iopub.status.idle":"2024-01-13T07:49:17.024112Z","shell.execute_reply.started":"2024-01-13T07:49:16.903363Z","shell.execute_reply":"2024-01-13T07:49:17.023041Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(len(df_input))\nprint(len(df_target))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:17.025863Z","iopub.execute_input":"2024-01-13T07:49:17.026161Z","iopub.status.idle":"2024-01-13T07:49:17.030698Z","shell.execute_reply.started":"2024-01-13T07:49:17.026135Z","shell.execute_reply":"2024-01-13T07:49:17.029668Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"49607\n49607\n","output_type":"stream"}]},{"cell_type":"code","source":"idx = 50\nprint(f'{df_input[idx]}')\nprint(f'{df_target[idx]}')\nprint(f'{df_concat[idx]}')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:17.035686Z","iopub.execute_input":"2024-01-13T07:49:17.036059Z","iopub.status.idle":"2024-01-13T07:49:17.041916Z","shell.execute_reply.started":"2024-01-13T07:49:17.036033Z","shell.execute_reply":"2024-01-13T07:49:17.040817Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"همی بر شد آتش فرود آمد آب\n <s> همی گشت گرد زمین آفتاب   گیا رست با چند گونه درخت    به زیر اندر آمد سرانشان ز بخت  </s>  \nهمی بر شد آتش فرود آمد آب <s> همی گشت گرد زمین آفتاب   گیا رست با چند گونه درخت    به زیر اندر آمد سرانشان ز بخت  </s>  \n","output_type":"stream"}]},{"cell_type":"code","source":"\nprint(tokenizer.encode(\"<s>گیا رست با چند گونه درخت    به زیر اندر آمد سرانشان ز بخت</s>\"))\nprint(tokenizer.encode(\"<s>\"))\nprint(tokenizer.encode(\"</s>\"))\nprint(tokenizer.encode(\"<pad>\"))\nprint(tokenizer.encode(\"<|startoftext|>\"))\nprint(tokenizer.encode(\"<sep>\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:17.043046Z","iopub.execute_input":"2024-01-13T07:49:17.043312Z","iopub.status.idle":"2024-01-13T07:49:17.053060Z","shell.execute_reply.started":"2024-01-13T07:49:17.043289Z","shell.execute_reply":"2024-01-13T07:49:17.052097Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[0, 423, 268, 2630, 314, 638, 1752, 3087, 21147, 303, 730, 15233, 2199, 3325, 549, 355, 11653, 2]\n[0]\n[2]\n[1]\n[6]\n[9]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## MultiGPU setup","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:17.054640Z","iopub.execute_input":"2024-01-13T07:49:17.054959Z","iopub.status.idle":"2024-01-13T07:49:18.139994Z","shell.execute_reply.started":"2024-01-13T07:49:17.054933Z","shell.execute_reply":"2024-01-13T07:49:18.139019Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Sat Jan 13 07:49:17 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   33C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ndef set_up_two_gpus():\n    available_gpus = torch.cuda.device_count()\n    if available_gpus < 2:\n        raise ValueError(\"Insufficient number of GPUs available. Need at least two GPUs.\")\n\n    device_1 = torch.device(\"cuda:0\")\n    device_2 = torch.device(\"cuda:1\")\n\n    print(f\"Available GPUs: {available_gpus}\")\n    print(f\"Setting GPU 0 as device: {device_1}\")\n    print(f\"Setting GPU 1 as device: {device_2}\")\n\n    return device_1, device_2\n\n# Check and print if the GPUs are working by performing a computational operation\ndef check_gpu(device):\n    tensor = torch.randn(1000, 1000, device=device)\n    result = torch.matmul(tensor, tensor)\n    return result\n\n# Usage\ndevice_1, device_2 = set_up_two_gpus()\nresult_1 = check_gpu(device_1)\nresult_2 = check_gpu(device_2)\nprint(\"Results from GPU 0:\", result_1)\nprint(\"Results from GPU 1:\", result_2)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:18.141550Z","iopub.execute_input":"2024-01-13T07:49:18.141885Z","iopub.status.idle":"2024-01-13T07:49:18.926373Z","shell.execute_reply.started":"2024-01-13T07:49:18.141856Z","shell.execute_reply":"2024-01-13T07:49:18.925338Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Available GPUs: 2\nSetting GPU 0 as device: cuda:0\nSetting GPU 1 as device: cuda:1\nResults from GPU 0: tensor([[ 75.6320,  31.3526,  64.5673,  ...,  13.4411, -11.9168,  34.0021],\n        [-18.1419,  -7.9399,  35.6506,  ..., -75.3446,  26.5143, -28.9744],\n        [ -7.3059,  42.9290, -25.3374,  ...,  -9.7965,  27.7825, -22.4071],\n        ...,\n        [ 13.8088,   7.8570,  12.9168,  ...,  29.4321,  32.3362, -18.7860],\n        [-15.4928,  24.0701, -32.4685,  ...,  17.1769, -24.8387, -59.2409],\n        [ 37.2607,  21.3787, -12.6041,  ...,  34.6673,  -6.4960,  31.2525]],\n       device='cuda:0')\nResults from GPU 1: tensor([[ 1.4109e+01,  1.4025e+00, -3.8026e+01,  ...,  1.7126e+01,\n         -7.0841e+00, -1.6453e+01],\n        [ 3.0766e+01,  8.0499e+00,  1.6201e+01,  ..., -3.0754e+01,\n         -4.8530e+01, -1.5427e+01],\n        [-2.0524e+01,  2.5253e+01,  1.7683e+01,  ...,  5.1375e+01,\n          2.5864e+01,  8.7076e+00],\n        ...,\n        [-3.0036e+00, -1.7768e+01, -2.9617e+00,  ..., -4.5509e+01,\n         -3.1695e+01, -6.9207e-02],\n        [ 2.6086e+01,  1.9729e+01, -3.6439e+01,  ..., -2.4470e+01,\n         -4.2639e+01, -1.0230e+01],\n        [-3.5930e-01,  2.0712e+01, -1.4659e+01,  ..., -8.4033e+01,\n         -8.6827e+00, -2.2168e+01]], device='cuda:1')\n","output_type":"stream"}]},{"cell_type":"code","source":"# Sample input text\ninput_text = df_input[50]\n# Tokenize and encode the input text\ninput_encoding = tokenizer.encode(input_text)\n\n# Decode the tokenized input back to text\ndecoded_input = tokenizer.decode(input_encoding)\n\n# Print results\nprint(\"Original Text:\", input_text)\nprint(\"Tokenized Input:\", input_encoding)\nprint(\"Decoded Input:\", decoded_input)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:18.927531Z","iopub.execute_input":"2024-01-13T07:49:18.927873Z","iopub.status.idle":"2024-01-13T07:49:18.935099Z","shell.execute_reply.started":"2024-01-13T07:49:18.927847Z","shell.execute_reply":"2024-01-13T07:49:18.934097Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Original Text: همی بر شد آتش فرود آمد آب\nTokenized Input: [272, 398, 327, 403, 2466, 2638, 2199, 797]\nDecoded Input: همی بر شد آتش فرود آمد آب\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset  \nimport torch\ntorch.manual_seed(42)\nclass MTGDataset(Dataset):\n    def __init__(self, input_texts, tokenizer, max_length=1024):\n        self.tokenizer = tokenizer  \n        self.input_ids = []\n        self.attn_masks = []\n\n        for txt in input_texts:\n            encodings_dict = tokenizer(txt ,\n                                       truncation=True,\n                                       max_length=max_length,\n                                       padding=\"max_length\")\n            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n\n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.attn_masks[idx]","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:18.936350Z","iopub.execute_input":"2024-01-13T07:49:18.936659Z","iopub.status.idle":"2024-01-13T07:49:18.948802Z","shell.execute_reply.started":"2024-01-13T07:49:18.936634Z","shell.execute_reply":"2024-01-13T07:49:18.947908Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\nmax_seq = 256\ndataset = MTGDataset(df_concat, tokenizer, max_length=max_seq)\n# Split into training and validation sets\ntrain_size = int(0.9 * len(dataset))\nval_size = (len(dataset) - train_size)\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\nf'There are {len(train_dataset)} samples for training, and {len(val_dataset)} samples for validation testing'","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:18.949978Z","iopub.execute_input":"2024-01-13T07:49:18.950234Z","iopub.status.idle":"2024-01-13T07:49:43.622902Z","shell.execute_reply.started":"2024-01-13T07:49:18.950211Z","shell.execute_reply":"2024-01-13T07:49:43.621916Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'There are 44646 samples for training, and 4961 samples for validation testing'"},"metadata":{}}]},{"cell_type":"code","source":"import random\nfrom transformers import GPT2LMHeadModel, GPT2Config\nimport numpy as np\n\n# Loading the model configuration and setting it to the GPT2 standard settings.\nconfiguration = GPT2Config.from_pretrained('/kaggle/working/gpt2-fa/', output_hidden_states=False)\n\n# Create the instance of the model and set the token size embedding length\nmodel = GPT2LMHeadModel.from_pretrained(\"/kaggle/working/gpt2-fa/\", config=configuration)\nmodel.resize_token_embeddings(len(tokenizer))\n\n\n# This step is optional but will enable reproducible runs.\nseed_val = 42\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:43.624260Z","iopub.execute_input":"2024-01-13T07:49:43.624893Z","iopub.status.idle":"2024-01-13T07:49:44.611513Z","shell.execute_reply.started":"2024-01-13T07:49:43.624855Z","shell.execute_reply":"2024-01-13T07:49:44.610477Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"epochs = 3\nwarmup_steps = 1e2\nsample_every = 300","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:44.612957Z","iopub.execute_input":"2024-01-13T07:49:44.613374Z","iopub.status.idle":"2024-01-13T07:49:44.619189Z","shell.execute_reply.started":"2024-01-13T07:49:44.613335Z","shell.execute_reply":"2024-01-13T07:49:44.618112Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\n# AdamW is a class from the huggingface library, it is the optimizer we will be using, and we will only be instantiating it with the default parameters.\noptimizer = AdamW(\n    model.parameters(),\n    lr=5e-4,\n    eps=1e-8,\n    no_deprecation_warning=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:44.620472Z","iopub.execute_input":"2024-01-13T07:49:44.620881Z","iopub.status.idle":"2024-01-13T07:49:44.649911Z","shell.execute_reply.started":"2024-01-13T07:49:44.620854Z","shell.execute_reply":"2024-01-13T07:49:44.649153Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\ntrain_dataloader = DataLoader(\n    train_dataset,\n    sampler=RandomSampler(train_dataset),\n    batch_size=8\n)\n\nvalidation_dataloader = DataLoader(\n    val_dataset,\n    sampler=SequentialSampler(val_dataset),\n    batch_size=8\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:44.650931Z","iopub.execute_input":"2024-01-13T07:49:44.651219Z","iopub.status.idle":"2024-01-13T07:49:44.656712Z","shell.execute_reply.started":"2024-01-13T07:49:44.651194Z","shell.execute_reply":"2024-01-13T07:49:44.655808Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=total_steps)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:44.657841Z","iopub.execute_input":"2024-01-13T07:49:44.658107Z","iopub.status.idle":"2024-01-13T07:49:44.664846Z","shell.execute_reply.started":"2024-01-13T07:49:44.658083Z","shell.execute_reply":"2024-01-13T07:49:44.663997Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.nn import DataParallel\n# Define a function to set up multi-GPU training\ndef multi_gpu_setup(model):\n    if torch.cuda.device_count() > 1:\n        print(f\"Using {torch.cuda.device_count()} GPUs\")\n        model = DataParallel(model)\n    return model\n\n# Use the function to set up multi-GPU training\nmodel = multi_gpu_setup(model)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:44.665984Z","iopub.execute_input":"2024-01-13T07:49:44.666356Z","iopub.status.idle":"2024-01-13T07:49:44.675336Z","shell.execute_reply.started":"2024-01-13T07:49:44.666321Z","shell.execute_reply":"2024-01-13T07:49:44.674404Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nif device.type == 'cuda':\n    print(f\"Memory Allocated: {torch.cuda.memory_allocated(device)/1024**3:.2f} GB\")\n    print(f\"Memory Cached: {torch.cuda.memory_cached(device)/1024**3:.2f} GB\")\nelse:\n    print(\"CUDA is not available. Switching to CPU.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:44.676475Z","iopub.execute_input":"2024-01-13T07:49:44.676813Z","iopub.status.idle":"2024-01-13T07:49:44.687507Z","shell.execute_reply.started":"2024-01-13T07:49:44.676761Z","shell.execute_reply":"2024-01-13T07:49:44.686473Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Using device: cuda\nMemory Allocated: 0.01 GB\nMemory Cached: 0.02 GB\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:416: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"\nsample_input = df_input[np.random.randint(0, len(df_input))]\nprint(sample_input)\nsample_input_ids = torch.tensor(tokenizer([sample_input])[\"input_ids\"])\nsample_input_ids = sample_input_ids.to('cpu')\n\nsample_outputs = model.module.generate(\n    input_ids=sample_input_ids,\n    do_sample=True,\n    top_k=50,\n    max_length=50,\n    top_p=0.95,\n    num_return_sequences=5\n)\nfor i, sample_output in enumerate(sample_outputs):\n    gen_sample_output = tokenizer.decode(sample_output, skip_special_tokens=False)\n    gen_sample_output = gen_sample_output.replace(\"<|startoftext|>\", \"\\n\")\n    gen_sample_output = gen_sample_output.replace(\"<s>\", \"\")\n    gen_sample_output = gen_sample_output.replace(\"</s>\", \"\")\n    gen_sample_output = gen_sample_output.replace(\"<sep>\", \"\\n\")\n\n    print(f'Example output: {gen_sample_output}')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:44.688890Z","iopub.execute_input":"2024-01-13T07:49:44.689755Z","iopub.status.idle":"2024-01-13T07:49:48.540308Z","shell.execute_reply.started":"2024-01-13T07:49:44.689721Z","shell.execute_reply":"2024-01-13T07:49:48.539320Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"جوان گرچه دانا بود با گهر\nExample output: جوان گرچه دانا بود با گهربار و با فراستش این کار را کرد و مردم را برانداخت به تباهی. پس از او، نوبت به یزدگرد رسید. سپاه به سوی غرب رفت. سپاه عرب در آن سوی جیحون (که در زبان فارسی از\nExample output: جوان گرچه دانا بود با گهربار عشق» اما در این میان که چه چیزی از قلم افتاده است. در این میان می‌بینم «ای مردم، چرا نباید در دل آتش به گریه بیفتد؟» تا این که یک نفر از مردم «هست\nExample output: جوان گرچه دانا بود با گهربار که این هم یک بار خیلی هم آدم را خسته نکرد و از فرط خستگی به خودش آمد. او را با این حال صدا می‌کند، می‌گوید: «با همین حال می‌توانم به خودم امید\nExample output: جوان گرچه دانا بود با گهربار در کوچه پس‌کوچه‌ها قدم زد. با صدای آواز دلکش و نغمه‌هایی دلنشین از بنان. به آواز روح می‌افروزم و آرام می‌نشیند. می‌آید و می‌نشیند\nExample output: جوان گرچه دانا بود با گهربار و با خود می‌گوید من هنوز به اندازهٔ تو برای زندگی کردن احتیاج دارم (پس من هم به همین نسبت احتیاج دارم) و فقط وقتی بزرگ شدم این مشکل‌ها را برطرف و از آن‌ها\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install tqdm","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:49:48.541597Z","iopub.execute_input":"2024-01-13T07:49:48.542420Z","iopub.status.idle":"2024-01-13T07:50:00.671156Z","shell.execute_reply.started":"2024-01-13T07:49:48.542388Z","shell.execute_reply":"2024-01-13T07:50:00.670030Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:50:00.672876Z","iopub.execute_input":"2024-01-13T07:50:00.673689Z","iopub.status.idle":"2024-01-13T07:50:00.679685Z","shell.execute_reply.started":"2024-01-13T07:50:00.673646Z","shell.execute_reply":"2024-01-13T07:50:00.678691Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:50:00.681273Z","iopub.execute_input":"2024-01-13T07:50:00.681713Z","iopub.status.idle":"2024-01-13T07:50:00.690481Z","shell.execute_reply.started":"2024-01-13T07:50:00.681676Z","shell.execute_reply":"2024-01-13T07:50:00.689491Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"\ntraining_args = TrainingArguments(\n    output_dir=\"./output\",\n    num_train_epochs=2,\n    per_device_train_batch_size=32,\n    learning_rate=5e-5,\n    logging_steps=500,\n    save_steps=1000,\n    evaluation_strategy=\"steps\",\n    eval_steps=1000,\n    # Add distributed training options\n    per_device_eval_batch_size=32,\n    fp16=True,  # Enable mixed-precision training if supported\n    dataloader_num_workers=16,  # Adjust based on your system capabilities\n    report_to=\"tensorboard\",  # You can use TensorBoard for logging\n)\n\n# Initialize Trainer object\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    tokenizer=tokenizer,\n)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:50:54.431414Z","iopub.execute_input":"2024-01-13T07:50:54.431828Z","iopub.status.idle":"2024-01-13T07:50:54.445390Z","shell.execute_reply.started":"2024-01-13T07:50:54.431796Z","shell.execute_reply":"2024-01-13T07:50:54.444362Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import random\nimport time\nimport datetime\ndef format_time(elapsed):\n    return str(datetime.timedelta(seconds=int(round((elapsed)))))\ntotal_t0 = time.time()\ntraining_stats = []\nmodel = model.to(device)\nfor epoch_i in tqdm(range(training_args.num_train_epochs),position=0):\n    print(f'Beginning epoch {epoch_i + 1} of {training_args.num_train_epochs}')\n    t0 = time.time()\n    total_train_loss = 0\n    model.train()\n    for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader), position=0):\n        b_input_ids = batch[0].to(device)\n        b_labels = batch[0].to(device)\n        b_masks = batch[1].to(device)\n        model.zero_grad()\n        outputs = model(b_input_ids, labels=b_labels, attention_mask=b_masks, token_type_ids=None)\n        loss = outputs.loss\n        loss = loss.mean()\n        batch_loss = loss\n        total_train_loss += batch_loss\n        # Get sample every 100 batches.\n        if step % sample_every == 0 and not step == 0:\n            elapsed = format_time(time.time() - t0)\n            print()\n            print(f'Batch {step} of {len(train_dataloader)}. Loss:{batch_loss}. Time:{elapsed}')\n            model.eval()\n            sample_input = df_input[np.random.randint(0, len(df_input))]\n            print(sample_input)\n            sample_input_ids = torch.tensor(tokenizer([sample_input])[\"input_ids\"])\n            sample_input_ids = sample_input_ids.to(device)\n            sample_outputs = model.module.generate(\n                input_ids=sample_input_ids,\n                do_sample=True,\n                top_k=50,\n                max_length=50,\n                top_p=0.95,\n                num_return_sequences=1\n            )\n            for i, sample_output in enumerate(sample_outputs):\n                gen_sample_output = tokenizer.decode(sample_output, skip_special_tokens=False)\n                gen_sample_output = gen_sample_output.replace(\"<|startoftext|>\", \"\\n\")\n                gen_sample_output = gen_sample_output.replace(\"<s>\", \"\")\n                gen_sample_output = gen_sample_output.replace(\"</s>\", \"\")\n                gen_sample_output = gen_sample_output.replace(\"<sep>\", \"\\n\")\n                print(f'Example output: {gen_sample_output}')\n            model.train()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n    # Calculate the average loss over all of the batches.\n    avg_train_loss = total_train_loss / len(train_dataloader)\n    # Measure how long this epoch took.\n    training_time = format_time(time.time() - t0)\n    print()\n    print(f'Average Training Loss: {avg_train_loss}. Epoch time: {training_time}')\n    print()\n    t0 = time.time()\n    model.eval()\n    total_eval_loss = 0\n    nb_eval_steps = 0\n    # Evaluate data for one epoch\n    for batch in tqdm(validation_dataloader, total=len(validation_dataloader), position=0):\n        b_input_ids = batch[0].to(device)\n        b_labels = batch[0].to(device)\n        b_masks = batch[1].to(device)\n        with torch.no_grad():\n            outputs = model(b_input_ids, attention_mask=b_masks, labels=b_labels)\n            loss = outputs.loss\n            loss = loss.mean()\n            batch_loss = loss\n        total_eval_loss += batch_loss\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    validation_time = format_time(time.time() - t0)\n    print()\n    print(f'Validation loss: {avg_val_loss}. Validation Time: {validation_time}')\n    print()\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(f'Total training took {format_time(time.time()-total_t0)}')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T07:50:55.963146Z","iopub.execute_input":"2024-01-13T07:50:55.964043Z","iopub.status.idle":"2024-01-13T09:10:00.394958Z","shell.execute_reply.started":"2024-01-13T07:50:55.964007Z","shell.execute_reply":"2024-01-13T09:10:00.393933Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c17b03b7fe4e49c8a4fb243b75c9c952"}},"metadata":{}},{"name":"stdout","text":"Beginning epoch 1 of 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5581 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6cf97d837a496eb79e1cecc7aaf8c8"}},"metadata":{}},{"name":"stdout","text":"\nBatch 300 of 5581. Loss:0.5782329440116882. Time:0:01:59\nجوان گرچه دانا بود با گهر\nExample output: جوان گرچه دانا بود با گهر   که برتهٔ خویش کز شاه جهان بود   چو باد آمد بر سر او  \n\nBatch 600 of 5581. Loss:0.5162903070449829. Time:0:04:02\nببستند یارانش یکسر کمر\nExample output: ببستند یارانش یکسر کمر  بفرمود و بر هر جای   بدانگه که آمد لشکر چو باد    همه پاک یزدان بر باد  \n\nBatch 900 of 5581. Loss:0.526287317276001. Time:0:06:04\nنوندی ز گفتار کارآگهان\nExample output: نوندی ز گفتار کارآگهان  نگردد نه هنگام مهتران کهن   وزان سان که بشنید زان گونه جنگ    همی گیرد به یک سو بگفت و چون شنید  \n\nBatch 1200 of 5581. Loss:0.49642834067344666. Time:0:08:07\nسرانجام اگر راه جویی بداد\nExample output: سرانجام اگر راه جویی بداد  که چون باده در جنگ جویی بداد   یکی تیغ زن را بر کرد و برکشید    پس پشت او از دشت در گذشت  \n\nBatch 1500 of 5581. Loss:0.4387779235839844. Time:0:10:09\nبسی آفرین کرد بر شهریار\nExample output: بسی آفرین کرد بر شهریار  به ابر اندر آمد و باد بهار   ز ایران بسی نامدارانش    ز هر نامداری و هر مهتری  \n\nBatch 1800 of 5581. Loss:0.43419432640075684. Time:0:12:12\nبرانگیزم از گاه کاووس را\nExample output: برانگیزم از گاه کاووس را  اگر دور شوم یکسر همه بوم را   بدین مرز من آن بوم و بر    نمانم بر بدکنش را  \n\nBatch 2100 of 5581. Loss:0.41692179441452026. Time:0:14:14\nسواران ز بس رنج و اسبان ز تگ\nExample output: سواران ز بس رنج و اسبان ز تگ  همی هر زمان بیامد به آوردگاه   که هر کس که بدخواه بود    ز لشکر جهاندار و بیدار بود  \n\nBatch 2400 of 5581. Loss:0.4446583688259125. Time:0:16:17\nبیامد بر تاجور سوفزای\nExample output: بیامد بر تاجور سوفزای  که خوانی همی کرد بر نامجوی   به ایران رسید و بستد بر تخت عاج    ز زرینهٔ کردگار بلند  \n\nBatch 2700 of 5581. Loss:0.4516196846961975. Time:0:18:19\nازان پس بران تیرگی بگذرم\nExample output: ازان پس بران تیرگی بگذرم  نگر تا نگردد یکی چاره برم   که اگر شاه در ایران بود    ببد بر چو او شاد بودمش ز جای  \n\nBatch 3000 of 5581. Loss:0.3744736611843109. Time:0:20:21\nز گیتی برو بر کنند آفرین\nExample output: ز گیتی برو بر کنند آفرین  ز دادار نیکی دهش و زمین   دگر هفته را روز دیگر گذشت    چنان پر از بوی و رنگ و آب گشت  \n\nBatch 3300 of 5581. Loss:0.44976863265037537. Time:0:22:24\nگنهکار یزدانی وناسپاس\nExample output: گنهکار یزدانی وناسپاسپ کرد  چو از کاردانان پیشین کرد   همی داشت زان سخن بر دو فرسنگ شست    که در بیشهٔ نارون داشتی خار شست  \n\nBatch 3600 of 5581. Loss:0.4459182918071747. Time:0:24:26\nکنون چون زنان پیش من بسته دست\nExample output: کنون چون زنان پیش من بسته دست  به پیش اندرش را خروشان ببست   به خون پدر زار و پیچان بدند    ورا پر از آب مژگان پر از خون بدند  \n\nBatch 3900 of 5581. Loss:0.40361493825912476. Time:0:26:29\nچهارم چنین گفت شاه جهان\nExample output: چهارم چنین گفت شاه جهان  که با نامداران و من مهان مهان   گر ایرانیان از پس اندر به پای آورند    شود تیره کین رای دیگر برند  \n\nBatch 4200 of 5581. Loss:0.37970584630966187. Time:0:28:31\nیکی داستان زد جهاندیده کی\nExample output: یکی داستان زد جهاندیده کی  به راه آورد این کیانی پی   به گفتار شاه اردشیر    ازان گفته بودند ناباک زاد  \n\nBatch 4500 of 5581. Loss:0.40470463037490845. Time:0:30:34\nنگوید سخن جز همه راستی\nExample output: نگوید سخن جز همه راستی  کزان پس نخواهد کزان کاستی   ز هر نیکویی در گمان    که نترسی شود بی گمان  \n\nBatch 4800 of 5581. Loss:0.3594628572463989. Time:0:32:36\nپرستنده گفتا چو فرمان دهی\nExample output: پرستنده گفتا چو فرمان دهی  ز ایران بدان بد مر آن را رهی   همی گفت هرکس که ای شاه زاد    چرا ماند اندر جهان یادگار  \n\nBatch 5100 of 5581. Loss:0.4108995795249939. Time:0:34:39\nترا آشتی بهتر آید ز جنگ\nExample output: ترا آشتی بهتر آید ز جنگ سیر  ازیشان فراوان بگردان ستیز   چو آمد بنزدیک رستم رسید    بر آمد خروش اندر آورد دید  \n\nBatch 5400 of 5581. Loss:0.3076521158218384. Time:0:36:41\nمبادا ز تو تخت پردخت و گاه\nExample output: مبادا ز تو تخت پردخت و گاه  تهی ماند از گنج نیکی خواه   چو نامه بخوانی یکایک به راز    نگه کن چنین تا چه فرمان فراز  \n\nAverage Training Loss: 0.466329425573349. Epoch time: 0:37:55\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/621 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6077f22d142b4ebdbd34ea23b1597844"}},"metadata":{}},{"name":"stdout","text":"\nValidation loss: 0.3681398332118988. Validation Time: 0:01:37\n\nBeginning epoch 2 of 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5581 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c8a58cad4ff4b779b06bd83fe4062ba"}},"metadata":{}},{"name":"stdout","text":"\nBatch 300 of 5581. Loss:0.3541761338710785. Time:0:02:02\nبه تاراج داد آن همه خواسته\nExample output: به تاراج داد آن همه خواسته  زمین گشت آراسته چون بهشتی شد آراسته   چو این نامه برخواند پیشش دبیر    به دستوری تیز و پاسخ دلپذیر  \n\nBatch 600 of 5581. Loss:0.3396536111831665. Time:0:04:05\nسپاهش بکوه کنابد شود\nExample output: سپاهش بکوه کنابد شود  وزو بوم ویران ویران شود   چو از شهر ایران نتابی نکوست    که با لشکرش یار باید نخست  \n\nBatch 900 of 5581. Loss:0.29625922441482544. Time:0:06:07\nازان درد بگریست افراسیاب\nExample output: ازان درد بگریست افراسیاب  که هنگام آرام یافتی کباب   بباشد همی آفتاب و ماه    مگر کشته شد کشته در زیر گاه  \n\nBatch 1200 of 5581. Loss:0.32953953742980957. Time:0:08:09\nبفرمود تا زو بپرسند شاه\nExample output: بفرمود تا زو بپرسند شاه  که آمد به ما تاج بر سر کلاه   مگر پیش من سر بپیچد ز داد    نه اندیشد از جان و دل به چیز  \n\nBatch 1500 of 5581. Loss:0.35165882110595703. Time:0:10:12\nترا بهتر آید که فرمان کنی\nExample output: ترا بهتر آید که فرمان کنی  زبان را به پیمان گروگان کنی   بر آیین شاهان پیشین رویم    سخن هر چه پرسیم در نهان بشنویم  \n\nBatch 1800 of 5581. Loss:0.311448335647583. Time:0:12:15\nز تو دور شد فره و بخردی\nExample output: ز تو دور شد فره و بخردی  دلت را ز اندیشه اندر سخن   دلت را از اندیشه و کردار او    ازویست آرام و گفتار او  \n\nBatch 2100 of 5581. Loss:0.3303575813770294. Time:0:14:17\nبه گیتی نگر کین هنرها کراست\nExample output: به گیتی نگر کین هنرها کراست  که با جان پاکت دلست   ازیشان مرا چند بگریختی    که تا من ببستم چنین کیی  \n\nBatch 2400 of 5581. Loss:0.3419315814971924. Time:0:16:19\nبه طرخان چنین گفت کای سرفراز\nExample output: به طرخان چنین گفت کای سرفراز  ز گردان خسروپرست وفراز   بدین داستان زد یکی داستان    شنیدم که ای سرفرازان ز بن  \n\nBatch 2700 of 5581. Loss:0.3374219536781311. Time:0:18:21\nهمی زور و بخت از جهاندار دید\nExample output: همی زور و بخت از جهاندار دید  سر مرد باید که باید برید   چو آگاه شد شاه ز ایران سپاه    ز ایران و توران بیامد به راه  \n\nBatch 3000 of 5581. Loss:0.2594393491744995. Time:0:20:23\nنباشم همیدون من او را نیا\nExample output: نباشم همیدون من او را نیا  به رزم آمدی تیز روی نیا   بگفتا کزین سان شدم جنگجوی    دل وجان به مهر اندر آرم بروی  \n\nBatch 3300 of 5581. Loss:0.3159875273704529. Time:0:22:26\nبه شادی و انده نگردد دگر\nExample output: به شادی و انده نگردد دگر  مگر نیک گردد بدان هرچ آید ببر   ابا آنک گفتی سراسر سخن    ز یک یک سخن نگذرانی به بن  \n\nBatch 3600 of 5581. Loss:0.3406900465488434. Time:0:24:28\nنشسته برو شهریاری چو ماه\nExample output: نشسته برو شهریاری چو ماه  ازان نامداران بی تاج و گاه   به پیش سپاه اندر آمد چو پیل    زمین گشت از نعل سندان چو نیل  \n\nBatch 3900 of 5581. Loss:0.3067542612552643. Time:0:26:30\nبباید بریدن سر خویش پست\nExample output: بباید بریدن سر خویش پست  همه بند و نیرنگ و چاره بدست   چو گستاخ بشنید گفتار اوی    بدو تازه شد جان تاریک اوی  \n\nBatch 4200 of 5581. Loss:0.32000499963760376. Time:0:28:32\nبه نزد بزرگان ایرانیان\nExample output: به نزد بزرگان ایرانیان  بزرگان ایران و تخت کیان   چو پیران چنان دید برگشت گرد    نگه کرد و بر شاه شد لاژورد  \n\nBatch 4500 of 5581. Loss:0.28871119022369385. Time:0:30:34\nکنون روز دادست بیداد شد\nExample output: کنون روز دادست بیداد شد  برین آرزو دست بیکار شد   ز گیتی بشد هفتخوان پیش شاه    به هر سو همی کرد هر سو نگاه  \n\nBatch 4800 of 5581. Loss:0.29401087760925293. Time:0:32:37\nز بیگانه پردخته کردند جای\nExample output: ز بیگانه پردخته کردند جای  چو شد سست دل شد دل و راست رای   چو بر شاه بنشست و بگسست رنج    نکردست شادی و بخشش ز گنج  \n\nBatch 5100 of 5581. Loss:0.32135719060897827. Time:0:34:40\nسپهبد فرستاد نزدیک اوی\nExample output: سپهبد فرستاد نزدیک اوی  که ای شاه پیروز و سالار اوی   که چندین سرنامداران من    ستوده به شمشیر و شمشیر من  \n\nBatch 5400 of 5581. Loss:0.2936822474002838. Time:0:36:42\nز یک سو بیابان بی آب و نم\nExample output: ز یک سو بیابان بی آب و نم  گرفته سراپرده و خیمه ها   یکی سوی آن بیشه کز پیش بود    پر از جادوی بود و نابسود بود  \n\nAverage Training Loss: 0.326992392539978. Epoch time: 0:37:55\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/621 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"522a17c1685d499bb0f0c940b78ae8d9"}},"metadata":{}},{"name":"stdout","text":"\nValidation loss: 0.30382633209228516. Validation Time: 0:01:37\n\nTotal training took 1:19:04\n","output_type":"stream"}]},{"cell_type":"code","source":"save_path = \"trained.pth\"  \ntorch.save(model.state_dict(), save_path)\nprint(f'Model saved at: {save_path}')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T09:10:00.397123Z","iopub.execute_input":"2024-01-13T09:10:00.397829Z","iopub.status.idle":"2024-01-13T09:10:01.384975Z","shell.execute_reply.started":"2024-01-13T09:10:00.397788Z","shell.execute_reply":"2024-01-13T09:10:01.383928Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Model saved at: trained.pth\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## BLEU METRIC TEST ","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import corpus_bleu","metadata":{"execution":{"iopub.status.busy":"2024-01-13T09:25:16.841104Z","iopub.execute_input":"2024-01-13T09:25:16.841517Z","iopub.status.idle":"2024-01-13T09:25:17.285916Z","shell.execute_reply.started":"2024-01-13T09:25:16.841486Z","shell.execute_reply":"2024-01-13T09:25:17.285071Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"score = []\nmodel.eval()\n\nfor epoch_i in tqdm(range(training_args.num_train_epochs), position=0):\n    all_references = []\n    all_candidates = []\n\n    for batch in tqdm(validation_dataloader, total=len(validation_dataloader), position=0):\n        b_input_ids = batch[0].to(device)\n        b_labels = batch[0].to(device)\n        b_masks = batch[1].to(device)\n\n        with torch.no_grad():\n            outputs = model.module.generate(\n                input_ids=b_input_ids,\n                max_length=50,\n                num_return_sequences=5,\n                do_sample=True,\n                top_k=50,\n                top_p=0.95\n            )\n\n        references = [tokenizer.decode(ids, skip_special_tokens=True) for ids in b_labels]\n        \n        for i in range(len(outputs)):\n            gen_sample_output = tokenizer.decode(outputs[i], skip_special_tokens=True)\n            gen_sample_output = gen_sample_output.replace(\"<s>\", \"\")\n            gen_sample_output = gen_sample_output.replace(\"</s>\", \"\")\n            gen_sample_output = gen_sample_output.replace(\"<sep>\", \"\\n\")\n            \n            all_references.append([ref.split() for ref in references])\n            all_candidates.append(gen_sample_output.split())\n\n    bleu_score = corpus_bleu(all_references, all_candidates)\n    score.append(bleu_score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(score)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:22:26.878677Z","iopub.execute_input":"2024-01-13T10:22:26.879437Z","iopub.status.idle":"2024-01-13T10:22:26.884293Z","shell.execute_reply.started":"2024-01-13T10:22:26.879404Z","shell.execute_reply":"2024-01-13T10:22:26.883309Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"[1.0, 1.0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Generated Poem Samples","metadata":{}},{"cell_type":"code","source":"\nsample_input = df_input[np.random.randint(0, len(df_input))]\nprint(sample_input)\nsample_input_ids = torch.tensor(tokenizer([sample_input])[\"input_ids\"])\nsample_input_ids = sample_input_ids.to(device)\n\nsample_outputs = model.module.generate(\n    input_ids=sample_input_ids,\n    do_sample=True,\n    top_k=50,\n    max_length=50,\n    top_p=0.95,\n    num_return_sequences=5\n)\nfor i, sample_output in enumerate(sample_outputs):\n    gen_sample_output = tokenizer.decode(sample_output, skip_special_tokens=False)\n    gen_sample_output = gen_sample_output.replace(\"<|startoftext|>\", \"\\n\")\n    gen_sample_output = gen_sample_output.replace(\"<s>\", \"\")\n    gen_sample_output = gen_sample_output.replace(\"</s>\", \"\")\n    gen_sample_output = gen_sample_output.replace(\"<sep>\", \"\\n\")\n\n    print(f'Example output: {gen_sample_output}')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:23:52.050856Z","iopub.execute_input":"2024-01-13T10:23:52.051245Z","iopub.status.idle":"2024-01-13T10:23:52.766829Z","shell.execute_reply.started":"2024-01-13T10:23:52.051220Z","shell.execute_reply":"2024-01-13T10:23:52.765817Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"خود و سرکشان سوی جیحون کشید\nExample output: خود و سرکشان سوی جیحون کشید  که از آب دیده رخش ناپدید   یکی بانگ برزد به بیژن چو شیر    که با او به آوردگه گشت دیر  <pad><pad><pad><pad><pad><pad><pad>\nExample output: خود و سرکشان سوی جیحون کشید  سراسر ز داد یلان سر کشید   سپهبد چو پردخته شد ز آفرین    سپه را همه خواند و گفت کین  <pad><pad><pad><pad><pad><pad><pad><pad>\nExample output: خود و سرکشان سوی جیحون کشید  ز خون مژگان سراسر بر گل کشید   دو زلفش بسان دو نرگس به هم    چو کافور و با نار و سیب و به فندق دژم  \nExample output: خود و سرکشان سوی جیحون کشید  ز جیحون گذر کرد و جیحون کشید   چنان شد که پیران بدان جای جنگ    نیاسود و ننمود هرگز نهنگ  <pad><pad><pad><pad><pad><pad><pad>\nExample output: خود و سرکشان سوی جیحون کشید  همه کام او شد بی غم و درد و جوش   بدو گفت گر دل نداری فریب    نیابی فریب تو آورد گر نهیب  <pad><pad><pad><pad><pad>\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom nltk.translate.bleu_score import corpus_bleu\n\n# Assuming you have initialized your model, tokenizer, and have df_input, df_target, and df_concat\n\nindex = np.random.randint(0, len(df_input))\nsample_input = df_input[index]\nprint(f'Input sequence: {sample_input}')\n\nsample_input_ids = torch.tensor(tokenizer([sample_input])[\"input_ids\"])\nsample_input_ids = sample_input_ids.to(device)\nprint(f'Labeled target sequence: {df_concat[index]}')\n\nsample_outputs = model.module.generate(\n    input_ids=sample_input_ids,\n    do_sample=True,\n    top_k=50,\n    max_length=50,\n    top_p=0.95,\n    num_return_sequences=20\n)\n\nprint()\nprint('*' * 50)\nprint()\n\n# Prepare references for BLEU score calculation\nreferences = [df_concat[index].split()]  # Assuming df_concat[index] is a string\n\nfor i, sample_output in enumerate(sample_outputs):\n    gen_sample_output = tokenizer.decode(sample_output.tolist(), skip_special_tokens=True)\n    gen_sample_output = gen_sample_output.replace(\"<s>\", \"\")\n    gen_sample_output = gen_sample_output.replace(\"</s>\", \"\")\n    gen_sample_output = gen_sample_output.replace(\"<sep>\", \"\\n\")\n    \n    # Calculate BLEU score\n    bleu_score = corpus_bleu([references], [gen_sample_output.split()])\n    \n    print(f'Example output {i + 1}: {gen_sample_output} with BLEU score: {bleu_score}')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-13T10:42:47.027522Z","iopub.execute_input":"2024-01-13T10:42:47.028355Z","iopub.status.idle":"2024-01-13T10:42:47.737661Z","shell.execute_reply.started":"2024-01-13T10:42:47.028319Z","shell.execute_reply":"2024-01-13T10:42:47.736587Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Input sequence: بیابان گذارد به اندک سپاه\nLabeled target sequence: بیابان گذارد به اندک سپاه <s> شود شاه پیروز و دشمن تباه   بدان ای گزیده شه خسروان    که من هرچ گفتم نباشد جز آن  </s>  \n\n**************************************************\n\nExample output 1: بیابان گذارد به اندک سپاه  اگر کنده یی دور بیند سپاه   ببهرام نامه بد و بی وفا    ابا رای زن پیش جستی رها   with BLEU score: 0.14790264259417688\nExample output 2: بیابان گذارد به اندک سپاه  یکی را دهد آب و برگست راه   ز گرد سواران پرخاشجوی    بیازید و ز سرشان بتابید روی   with BLEU score: 0.14765979297062756\nExample output 3: بیابان گذارد به اندک سپاه  از ایدر که آیی به شادی به راه   همه لشکر آیدت زار و خوار    همه نامداران که آیدت کار زار   with BLEU score: 0.15337404749451009\nExample output 4: بیابان گذارد به اندک سپاه  ز گرد سواران در آن رزمگاه   که او را فگندی به خون ریختن    وزو روی گیتی پر انگیختن   with BLEU score: 0.15371371932217712\nExample output 5: بیابان گذارد به اندک سپاه  بدان تا بگیرند بر پشه راه   چو رستم که بودش سپه را نیاز    سپه را بفرمود رفتن نیاز   with BLEU score: 0.15371371932217712\nExample output 6: بیابان گذارد به اندک سپاه  نه دژ ماند ایدر نه شهر و نه راه   چنین تا دو سال اندر کشید    شد آنکس که با شاه در جنگ دید   with BLEU score: 0.14059391325479217\nExample output 7: بیابان گذارد به اندک سپاه  برآرند یکسر بماه و هور و ماه   ازین سان که بی ماه روی هوا    نباشد کسی رزم دیده سری   with BLEU score: 0.1588855641839972\nExample output 8: بیابان گذارد به اندک سپاه  تو ایدر بباشی بنزدیک شاه   بهومان چنین گفت سالار طوس    که پیش آید این لشکر و بوق و کوس   with BLEU score: 0.1588855641839972\nExample output 9: بیابان گذارد به اندک سپاه  تو را تیره آید ز خورشید و ماه   بباید ترا بی تو کشت و درود    مگر اختر سودمندت بماند ببل   with BLEU score: 0.14757581190431862\nExample output 10: بیابان گذارد به اندک سپاه  ز درگاه سالار بیدارخواه   که نزدیک او بود شیروی نام    سرافراز و دانا و شمشیر کام   with BLEU score: 0.1528571341245854\nExample output 11: بیابان گذارد به اندک سپاه  نیابند گذر پیش درگاه شاه   ازین کینه و آز بیرون شویم    ز پیکار بر مهر بیرون شویم   with BLEU score: 0.15346132816663713\nExample output 12: بیابان گذارد به اندک سپاه  کسی رابزد او پی هور و ماه   بدان تابه منذر ز نخچیرگاه    میان بسته دارم دو دیده براه   with BLEU score: 0.15371371932217712\nExample output 13: بیابان گذارد به اندک سپاه  نه بیند کسی را سر آید به راه   همه نامداران ایران گروه    کشیدند بر خاک پیش کوه   with BLEU score: 0.14108048489217512\nExample output 14: بیابان گذارد به اندک سپاه  همه تیغها بر نهاده به ماه   همی شد بران دشت سندی بچاج    یکی پرهنر مرد را دل زاج   with BLEU score: 0.14131251381458484\nExample output 15: بیابان گذارد به اندک سپاه  بریشان ز آوردگه کینه خواه   پس از من به فرمان خسرو شوی    همان راستی در جهان نو شوی   with BLEU score: 0.14790264259417688\nExample output 16: بیابان گذارد به اندک سپاه  همان پیل پیش آور ای نیک خواه   به دشت اندرون تیغ زن سی هزار    همه نامدار از در کارزار   with BLEU score: 0.14785967807080633\nExample output 17: بیابان گذارد به اندک سپاه  تو ایدر خرامش در پیش شاه   اگر کوه البرز بپیماید آب    از ایدر گذشتن ورا نیست خواب   with BLEU score: 0.14765979297062756\nExample output 18: بیابان گذارد به اندک سپاه  گر ایدونک جوید سپاهت به راه   بدان روی لشکر بکردار کوه    کشد گیو و بیژن چو توران همگروه   with BLEU score: 0.15371371932217712\nExample output 19: بیابان گذارد به اندک سپاه  سزد گر نخایی تو ای نیک خواه   دگر روز چون بردمد آفتاب    در آن گلشن پر از شادی و خواب و خواب   with BLEU score: 0.14611783090145075\nExample output 20: بیابان گذارد به اندک سپاه  تو در جنگ رستم بدین رزمگاه   ز ترکان کسی را که دانا بدند    دلیر و سبکسار و دانا بدند   with BLEU score: 0.1536690667279411\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}